=======================================================================
                        		CLUSTER MAINTAINANCE
 =======================================================================
 
BackupAndRestore:
  
    KUBERNETES backup and restore can be done by VALERO   formely called  ARK by HepIO
     https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/#backing-up-an-etcd-cluster
     
     https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/recovery.md
     ETCD BACKUP-RESTORE:
     https://github.com/mmumshad/kubernetes-the-hard-way/blob/master/practice-questions-answers/cluster-maintenance/backup-etcd/etcd-backup-and-restore.md
     
   - Backup ResourcesConfig:
      #To export all application deployments 
         kubectl get all --all-namespaces -o yaml > all-deploy-services.yml
   - Backup ETCD Cluster: 
       #To backup etcd cluster
          ETCDCTL_API=3	ectdctl snapshot save <filename.db>
       # To check the status of snaphot version and size
          ETCDCTL_API=3	ectdctl snapshot status <filename.db>
       
    - Restore ETCD Cluster:
      #Stop the kube-api server
         service kube-apiserver stop
      #and then 
          ETCDCTL_API=3	ectdctl snapshot save <filename.db> \
          --data-dir /var/lib/etcd-from-backup \
          --initial-cluster master-1=<ip-address:portNo>, master-2=<ip-address:portNo> \
          --initial-cluster-token etcd-cluster-1 \
          --initial-advertise-per-urls  https://${INTERNAL_IP}:2380
      #and then update following in 'etcd.service' 
         etcd.service=/usr/local/bin/etcd \
         --initial-cluster-token etcd-cluster-1 \
         --data-dir=/var/lib/etcd-from-backup 
      #and then restart service
        systemctl daemon-reload
        service etcd restart
      #Start the kube-api server
         service kube-apiserver stop
 
 Drain: 
   This is used to completely remove pods from one node and place/recreate them on other nodes.
   It is done in case of patching or OS Upgrades.  
    
   #To drain the node
     kubectl drain node01 #node01 is the nodename 
  
 Cordon: 
   This is used to prevent scheduling new pods on the node.
   
   #To cordon the node:
      kubectl cordon node01
   
 Uncordon: 
   This is used to resume scheduling of pods.
   
    #To uncordon the node.
      kubectl uncordon node01
      
 VERSIONS:      
    - In KUBERNETES  the following will have 'same version' (by deafult)
          - kube-apiserver  #  (can be at X.x version below object s can be at X.x-1 version )
          - control mgr
          - kube scheduler
          - kubectl           
          - kubelet  #(can be at X.x+1 version) kubelet alone can run container even the control plane is down.
          - kube-proxy 
     -  will have 'different versions'
         - coreDNS
         - ETCD Cluster
    #NOTE: Kube api server supports upto 2 minor versions for upgrade.

ClusterUpgradeUsingKubeadm:
 #NOTE: Kube api server supports upto 2 minor versions for upgrade
 #Upgrade should be done only to nearest minor versions only 

  # To upgrade Kubeadm and see the list of upgrades available 
    kubeadm upgrade plan    
       
  # To check the running pods
   kubectl get pods --all-namespaces -o wide
  
Masterupgrade:
         
   #Run the command to move the pods from master node to other nodes
     kubectl drain master --ignore-daemonsets
   #Run the command 
     apt install kubeadm=1.12.0-00 
   #and then 
     kubeadm upgrade apply v1.12.0 
   #and then to upgrade the kubelet on the master node 
     apt install kubelet=1.12.0-00 
   #and then
     kubectl uncordon master 

NodeUpgrade: 
  note: NODES SHOULD BE UPGRADED ONLY ONE AT A TIME IN A SEQUENTIAL ORDER TO AVOID DOWNTIME
  #Run this command to check the node version
   kubectl get nodes -o wide
  #Run the commands: 
    kubectl drain node01 --ignore-daemonsets
  #Run the commands to connect to node
    ssh node01
  #Run the commands: 
    apt install kubeadm=1.12.0-00 
  #and then 
    apt install kubelet=1.12.0-00
  #and then logout of it
      ctrl+D
  # and then in master 
    kubeadm upgrade node config --kubelet-version $(kubelet --version | cut -d ' ' -f 2)
  #Run this command to check the node version
    kubectl get nodes -o wide
  #and then to enable rescheduling 
    kubectl uncordon node01